{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n",
        "!pip install flash-attn --no-build-isolation\n",
        "!huggingface-cli download jinaai/jina-embeddings-v3 --local-dir ./models/jina-embeddings-v3"
      ],
      "metadata": {
        "id": "m68lMHXEnHOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeYyMRj-nGA6"
      },
      "outputs": [],
      "source": [
        "from torch.cuda import is_available as is_cuda_available\n",
        "from transformers import AutoModel\n",
        "\n",
        "# from xlm_roberta.modeling_lora import XLMRobertaLoRA\n",
        "\n",
        "model_folder = './models/jina-embeddings-v3/'\n",
        "\n",
        "# Initialize the model\n",
        "model = AutoModel.from_pretrained(model_folder, trust_remote_code=True, use_flash_attn=False)\n",
        "# model: XLMRobertaLoRA\n",
        "\n",
        "if is_cuda_available():\n",
        "    model.to('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wcHnagpnGA7",
        "outputId": "1381a028-23b7-4681-aeb1-c5da08ac3b1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 1024)\n",
            "[ 0.0736009  -0.08957924  0.0887474  ...  0.01675522 -0.00211969\n",
            "  0.00456729]\n"
          ]
        }
      ],
      "source": [
        "texts = [\n",
        "    \"sample text\",\n",
        "    \"Look at her face\",\n",
        "    \"a love song\",\n",
        "    \"a sad song\",\n",
        "]\n",
        "\n",
        "# When calling the `encode` function, you can choose a `task` based on the use case:\n",
        "# 'retrieval.query', 'retrieval.passage', 'separation', 'classification', 'text-matching'\n",
        "# Alternatively, you can choose not to pass a `task`, and no specific LoRA adapter will be used.\n",
        "query_embeddings = model.encode(texts, task=\"retrieval.query\")\n",
        "print(query_embeddings.shape)\n",
        "print(query_embeddings[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3CNQ_xEnGA7",
        "outputId": "6288986b-b1d1-4178-ce67-b151b1477a00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(57650, 1024)\n",
            "[-0.1406054  -0.04126596  0.02898028 ... -0.0118162  -0.0104178\n",
            " -0.00558778]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# load embeddings\n",
        "passage_embeddings = np.load('./jina-embeddings-v3_retrieval.passage.npy')\n",
        "print(passage_embeddings.shape)\n",
        "print(passage_embeddings[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Multi-threaded parallel MapReduce\n",
        "This approach utilizes Python's ThreadPoolExecutor to slice the similarity computation task and process it in parallel:\n",
        "Slicing (Map): The large-scale embedded matrix is sliced by rows into a number of small blocks, and each block calculates the similarity individually.\n",
        "Parallel Computing: Process multiple slices simultaneously through multiple threads, making full use of multi-core CPUs to improve computational efficiency.\n",
        "Reduce: Splice the similarity results of each slice into a complete similarity matrix.\n",
        "\n",
        "Applicable Scenarios:\n",
        "The embedding matrix is large and the memory of a single machine is not enough to load all the data at once."
      ],
      "metadata": {
        "id": "X8Rih86er5FS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBSLPrTInGA7",
        "outputId": "d0f772f8-c8c4-4e87-94f8-4b8db1b3d790"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MapReduce-style computation completed!\n",
            "[[0.11739243 0.20485012 0.15104674 ... 0.12595034 0.16781409 0.17875487]\n",
            " [0.3053073  0.11800735 0.15972804 ... 0.09573218 0.08708793 0.08289387]\n",
            " [0.30639645 0.35178605 0.37007502 ... 0.30292025 0.27659038 0.34594226]\n",
            " [0.32856753 0.30532134 0.310084   ... 0.22818434 0.3047609  0.3286222 ]]\n",
            "CPU times: user 173 ms, sys: 100 ms, total: 273 ms\n",
            "Wall time: 24.2 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_shard_similarity(shard, query_embeddings):\n",
        "    return query_embeddings @ shard.T\n",
        "\n",
        "# divide `passage_embeddings` into different pieces\n",
        "num_shards = 10\n",
        "shards = np.array_split(passage_embeddings, num_shards, axis=0)\n",
        "\n",
        "with ThreadPoolExecutor(max_workers=4) as executor:\n",
        "    shard_similarities = list(executor.map(compute_shard_similarity, shards, [query_embeddings] * len(shards)))\n",
        "\n",
        "\n",
        "similarities = np.hstack(shard_similarities)\n",
        "print(\"MapReduce-style computation completed!\")\n",
        "print(similarities)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. MapReduce based on map and functools.reduce\n",
        "This approach simulates the MapReduce workflow using Python's built-in map and functools.reduce:\n",
        "Map: Each slice of the embedded matrix is passed into the mapper function, which computes the similarity.\n",
        "Reduce: Merge the results of all the slices with functools.reduce to get the full similarity matrix.\n",
        "\n",
        "Applicable Scenarios:\n",
        "Embedded matrices are moderate and only need to be processed in a standalone environment."
      ],
      "metadata": {
        "id": "Xodea6anr31p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import functools\n",
        "import numpy as np\n",
        "\n",
        "# define mapper å’Œ reducer\n",
        "def mapper(shard):\n",
        "    shard_similarity = query_embeddings @ shard.T\n",
        "    return shard_similarity\n",
        "\n",
        "def reducer(p, c):\n",
        "    return np.hstack((p, c))\n",
        "\n",
        "# divide `passage_embeddings` into many pieces\n",
        "num_shards = 10\n",
        "shards = np.array_split(passage_embeddings, num_shards, axis=0)\n",
        "\n",
        "mapped = map(mapper, shards)\n",
        "reduced = functools.reduce(reducer, mapped)\n",
        "\n",
        "print(\"MapReduce-style computation completed!\")\n",
        "print(reduced)\n"
      ],
      "metadata": {
        "id": "DWMjsVXI-Gz8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a3b198c-63e8-4c31-b598-f28df59a7609"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MapReduce-style computation completed!\n",
            "[[0.11739243 0.20485012 0.15104674 ... 0.12595034 0.16781409 0.17875487]\n",
            " [0.3053073  0.11800735 0.15972804 ... 0.09573218 0.08708793 0.08289387]\n",
            " [0.30639645 0.35178605 0.37007502 ... 0.30292025 0.27659038 0.34594226]\n",
            " [0.32856753 0.30532134 0.310084   ... 0.22818434 0.3047609  0.3286222 ]]\n",
            "CPU times: user 154 ms, sys: 87 ms, total: 241 ms\n",
            "Wall time: 21 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison Summary\n",
        "Multi-threaded parallel MapReduce realizes parallel processing through thread pooling, which is more suitable for super-large-scale embedded matrix processing, especially in multi-core CPU environment, which can give full play to the hardware performance.\n",
        "\n",
        "MapReduce based on map and functools.reduce is more lightweight and suitable for medium-sized data processing, but performs better when computing resources are limited or the task size is small."
      ],
      "metadata": {
        "id": "bNuUhO8Xsmdj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Je0FEtFNnGA7",
        "outputId": "fef4fdc1-44ac-40b9-b2a7-963a376ddadc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[12383 46207 47392 12494 44620]\n",
            " [43615  4627 33356 20269  6894]\n",
            " [25317  1841 31527 44260 24504]\n",
            " [23647 32184 45343  4425 33847]]\n",
            "CPU times: user 9.95 ms, sys: 0 ns, total: 9.95 ms\n",
            "Wall time: 9.34 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# get top k indices\n",
        "top_k = 5\n",
        "top_k_indices = np.argsort(-similarities, axis=1)[:, :top_k]\n",
        "print(top_k_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEoZEMunnGA8",
        "outputId": "e11b0c0f-4fea-489c-e86d-a5e992abe0b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[12383 46207 47392 12494 44620]\n",
            " [43615  4627 33356 20269  6894]\n",
            " [25317  1841 31527 44260 24504]\n",
            " [23647 32184 45343  4425 33847]]\n",
            "CPU times: user 4.59 ms, sys: 0 ns, total: 4.59 ms\n",
            "Wall time: 6.17 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# a more efficient way to get top k indices\n",
        "num_queries = similarities.shape[0]\n",
        "arange = np.arange(num_queries)[:, None]\n",
        "\n",
        "top_k = 5\n",
        "top_k_indices = np.argpartition(-similarities, top_k, axis=1)[:, :top_k]\n",
        "# Sort the top_k indices to get them in order\n",
        "top_k_indices = top_k_indices[arange, np.argsort(-similarities[arange, top_k_indices])]\n",
        "print(top_k_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_tJ04XwAnGA8",
        "outputId": "0e1fadf6-1cbc-474e-906b-908c4fb3fd4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.31368357 0.30879918 0.3023354  0.30092064 0.3008294 ]\n",
            "[0.5256693  0.523084   0.5055026  0.49298722 0.48881698]\n",
            "[0.57650244 0.57347554 0.56800336 0.5575718  0.55670124]\n",
            "[0.6037559  0.58124775 0.57745135 0.5753776  0.55670756]\n"
          ]
        }
      ],
      "source": [
        "# print similarities for top k indices\n",
        "for i in range(len(top_k_indices)):\n",
        "    print(similarities[i, top_k_indices[i]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiUYQjlwnGA8"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "97YwIjvPnGA8",
        "outputId": "96dc05d1-d79b-4506-ff7d-cc833e297909",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          version https://git-lfs.github.com/spec/v1\n",
            "0  oid sha256:7cd19a8adf74791bfd99e1ccb8b1fc3bd2e...\n",
            "1                                      size 74864162\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_path = './spotify_millsongdata.csv'\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2IIv9SlnGA8"
      },
      "outputs": [],
      "source": [
        "# get entries for top k indices of query \"a love song\"\n",
        "top_k_entries = df.iloc[top_k_indices[-2]]\n",
        "print(top_k_entries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "MxkdyumYnGA8",
        "outputId": "a1655a69-cde9-48c3-cd69-98b610537cce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "positional indexers are out-of-bounds",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1713\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1714\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1715\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \"\"\"\n\u001b[0;32m-> 4153\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4154\u001b[0m         \u001b[0;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4133\u001b[0;31m         new_data = self._mgr.take(\n\u001b[0m\u001b[1;32m   4134\u001b[0m             \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_convert_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexers/utils.py\u001b[0m in \u001b[0;36mmaybe_convert_indices\u001b[0;34m(indices, n, verify)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"indices are out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: indices are out-of-bounds",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-9fefa3d16cf1>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get entries for top k indices of query \"a sad song\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtop_k_entries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop_k_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_k_entries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_deprecated_callable_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1741\u001b[0m         \u001b[0;31m# a list of integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_list_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m         \u001b[0;31m# a single integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_list_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1715\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m             \u001b[0;31m# re-raise with different error message, e.g. test_getitem_ndarray_3d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"positional indexers are out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAxisInt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: positional indexers are out-of-bounds"
          ]
        }
      ],
      "source": [
        "# get entries for top k indices of query \"a sad song\"\n",
        "top_k_entries = df.iloc[top_k_indices[-1]]\n",
        "print(top_k_entries)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}